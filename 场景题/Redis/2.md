## .设计一个榜单，要求是要实时维护，前100名的一个分数，你需要回答用什么样的数据结构，怎么样存储，然后这个榜单需要什么样的接口给用户提供什么样的接口13.好的，那我现在不是100名了，我有10万人，100万人，会有什么问题

### 实时榜单设计方案

#### 数据结构选择

对于实时榜单，我会选择以下 Redis 数据结构组合：

1. **Sorted Set (ZSET)**：存储所有用户的分数，用于快速排名
    - Key: `leaderboard:global`
    - Score: 用户分数
    - Member: 用户 ID
2. **Hash**：存储用户的额外信息（如用户名、头像、首次达分时间）
    - Key: `user:info:{userId}`
    - Field: 字段名（如`name`, `avatar`, `first_reach_time`）
3. **Top N 缓存**：定期将 Top N 数据缓存到内存
    - Key: `leaderboard:top100`
    - Value: 序列化的 Top 100 用户列表

#### 存储方案

- **主排行榜**：使用 Sorted Set 存储所有用户分数，保证插入、更新、查询排名的时间复杂度为 O (log N)
- **Top N 缓存**：定期（如每秒）从 Sorted Set 中获取 Top 100 并缓存，减轻热点查询压力
- **用户信息**：使用 Hash 结构存储，避免每次查询都需要访问数据库

python



运行









```python
import redis
import json
from datetime import datetime

class Leaderboard:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.main_leaderboard_key = "leaderboard:global"
        self.top_n_cache_key = "leaderboard:top100"
        self.top_n = 100
    
    def update_score(self, user_id, score, info=None):
        """更新用户分数并存储用户信息"""
        # 更新主排行榜
        self.redis.zadd(self.main_leaderboard_key, {user_id: score})
        
        # 存储用户信息
        if info:
            user_info_key = f"user:info:{user_id}"
            self.redis.hset(user_info_key, mapping=info)
        
        # 检查是否需要更新Top N缓存
        current_rank = self.redis.zrevrank(self.main_leaderboard_key, user_id)
        if current_rank < self.top_n:
            self._update_top_n_cache()
    
    def _update_top_n_cache(self):
        """更新Top N缓存"""
        top_users = self.redis.zrevrange(self.main_leaderboard_key, 0, self.top_n-1, withscores=True)
        top_list = []
        
        pipeline = self.redis.pipeline()
        for user_id, score in top_users:
            pipeline.hgetall(f"user:info:{user_id}")
        
        user_infos = pipeline.execute()
        
        for i, (user_id, score) in enumerate(top_users):
            info = user_infos[i]
            info = {k.decode(): v.decode() for k, v in info.items()} if info else {}
            top_list.append({
                "rank": i + 1,
                "user_id": user_id.decode(),
                "score": int(score),
                "info": info
            })
        
        self.redis.setex(self.top_n_cache_key, 60, json.dumps(top_list))
    
    def get_rank(self, user_id):
        """获取用户排名"""
        rank = self.redis.zrevrank(self.main_leaderboard_key, user_id)
        return rank + 1 if rank is not None else None
    
    def get_score(self, user_id):
        """获取用户分数"""
        score = self.redis.zscore(self.main_leaderboard_key, user_id)
        return int(score) if score is not None else 0
    
    def get_top_n(self):
        """获取Top N排行榜"""
        cached = self.redis.get(self.top_n_cache_key)
        if cached:
            return json.loads(cached)
        else:
            self._update_top_n_cache()
            return json.loads(self.redis.get(self.top_n_cache_key))
    
    def get_range(self, start, end):
        """获取指定排名范围的用户"""
        users = self.redis.zrevrange(self.main_leaderboard_key, start, end, withscores=True)
        result = []
        
        pipeline = self.redis.pipeline()
        for user_id, _ in users:
            pipeline.hgetall(f"user:info:{user_id}")
        
        user_infos = pipeline.execute()
        
        for i, (user_id, score) in enumerate(users):
            info = user_infos[i]
            info = {k.decode(): v.decode() for k, v in info.items()} if info else {}
            result.append({
                "rank": start + i + 1,
                "user_id": user_id.decode(),
                "score": int(score),
                "info": info
            })
        
        return result
```

#### 对外接口设计

1. **查询类接口**

    - `GET /leaderboard/top/100` - 获取 Top 100 榜单（从缓存读取）
    - `GET /leaderboard/user/{userId}` - 获取指定用户的排名和分数
    - `GET /leaderboard/range?start=100&end=200` - 获取排名 100-200 的用户

2. **更新类接口**

    - ```
     POST /leaderboard/update
     ```



     \- 更新用户分数

     json

     

     

     

     

     

     ```json
     {
       "userId": "123",
       "score": 1000,
       "info": {
         "name": "张三",
         "avatar": "http://example.com/avatar.png"
       }
     }
     ```

3. **批量接口**

    - `POST /leaderboard/batch/update` - 批量更新多个用户分数

### 数据量扩展到 10 万 / 100 万的挑战与解决方案

#### **主要挑战**

1. **内存占用**：Sorted Set 存储 100 万用户会占用约 100MB-200MB 内存
2. **热点问题**：Top N 查询集中访问 Redis
3. **更新性能**：频繁更新导致 Redis 压力增大
4. **数据持久化**：RDB/AOF 持久化影响性能

#### **解决方案**

1. **内存优化**
    - 使用 ziplist 编码：当成员数少于`zset-max-ziplist-entries`（默认 128）且值长度小于`zset-max-ziplist-value`（默认 64 字节）时，Sorted Set 使用更节省内存的 ziplist 结构
    - 定期清理低分用户：根据业务需求，清理长期不活跃的低分用户
2. **缓存策略优化**
    - 多级缓存：本地缓存（如 LRU 缓存）+ Redis 分布式缓存
    - 分层缓存：Top 100 高频访问数据单独缓存，降低 Redis 压力
    - 异步更新：使用消息队列异步更新 Top N 缓存，减少实时更新开销
3. **分片与集群**
    - 按业务维度分片：如按地区、类型分片
    - 使用 Redis Cluster：横向扩展，提高读写能力
4. **持久化策略调整**
    - 混合持久化：结合 RDB 和 AOF 的优点
    - 离线备份：重要数据定期导出到磁盘，降低实时持久化压力
5. **查询优化**
    - 范围查询优化：对大范围查询（如获取 10000-10100 名），采用索引优化或预计算
    - 懒加载用户信息：先返回排名和分数，用户信息按需加载

#### **性能测试参考**

在普通服务器配置（8 核 16G，SSD）下，Redis 可支持：

- 写入：约 10 万 QPS
- 读取：约 15 万 QPS
- 存储 100 万用户：约 150MB 内存（视 score 和 member 大小而定）