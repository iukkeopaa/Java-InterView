### HTTP 基于 TCP 还是 UDP？

HTTP（超文本传输协议）**基于 TCP 协议**工作。



原因在于，HTTP 的核心需求是**可靠的数据传输**：客户端发送的请求（如获取网页、提交表单）和服务器返回的响应（如 HTML 内容、图片）必须完整、有序地送达，不允许丢失或乱序 ―― 否则会导致网页显示异常、文件传输错误等问题。而 TCP 协议通过三次握手建立连接、确认机制、重传机制等特性，恰好能保证数据的可靠传输，满足 HTTP 的需求。



不过需要注意一个例外：**HTTP/3（最新的 HTTP 版本）基于 UDP 协议**。它通过 QUIC（一种基于 UDP 的传输层协议）实现，在保留 UDP 低延迟优势的同时，通过自身设计弥补了 UDP 的不可靠性（如增加重传、加密等机制），进一步优化了实时性和性能。但传统的 HTTP/1.1、HTTP/2 均基于 TCP。



综上，通常所说的 HTTP（尤其是主流的历史版本）基于 TCP；仅最新的 HTTP/3 基于 UDP。


### 为什么 HTTP/3 要做这个改变呢

HTTP/3 从 TCP 转向 UDP 的核心改变，主要是为了彻底解决 TCP 协议的两大固有缺陷，并充分利用 UDP 的灵活性实现性能跃升。以下是两大核心原因：

### 一、彻底解决 TCP 的 ** 队头阻塞（Head-of-Line Blocking）** 问题

TCP 是基于字节流的顺序传输协议，所有数据必须按顺序接收和确认。如果某个数据包丢失，即使后续数据包已到达，接收方也会被强制阻塞，直到丢失的包被重传并确认。这种现象在 HTTP/2 中尤为突出：虽然 HTTP/2 通过多路复用实现了应用层的并行传输，但 TCP 层的阻塞会导致所有数据流暂停，例如视频卡顿、网页加载中断等问题。



而 HTTP/3 通过**QUIC 协议**（基于 UDP）彻底解决了这一问题：



- **独立数据流**：每个 HTTP 请求对应 QUIC 中的一个独立 “流”，每个流的数据包单独传输和确认。即使某个流的数据包丢失，其他流仍可正常传输，不会相互影响。
- **灵活重传机制**：QUIC 在应用层实现重传逻辑，仅重传丢失的数据包，避免了 TCP 全局阻塞的问题。例如，在丢包率 5% 的网络环境下，HTTP/3 的加载速度比 HTTP/2 快 40%。

### 二、大幅减少**连接建立延迟**，提升弱网性能

TCP 的连接建立和加密握手需要多次往返时间（RTT）：



- **TCP 三次握手**：至少 1 个 RTT；
- **TLS 加密握手**：额外 1-2 个 RTT；
- **总计**：HTTP/2 首次连接需要 2-3 个 RTT，在高延迟网络（如跨国传输）中可能超过 300 毫秒。



HTTP/3 通过 QUIC 的**0-RTT 和 1-RTT 机制**彻底优化了这一过程：



- **0-RTT 连接**：对于重复访问的站点，客户端可直接复用之前的加密密钥，无需任何 RTT 即可发送数据。实测显示，移动网络下连接建立时间可减少 30-50%。
- **1-RTT 握手**：首次连接时，QUIC 将 TLS 握手与数据传输合并，仅需 1 个 RTT 即可完成加密协商和数据发送，相比 HTTP/2 减少 50% 以上的延迟。

### 三、额外优势：UDP 的灵活性与协议创新

除了上述两大核心原因，UDP 的特性还为 HTTP/3 带来了以下创新：



1. **连接迁移**：QUIC 使用 64 位随机数作为连接 ID，而非 TCP 的 “IP + 端口” 四元组。当设备切换网络（如从 Wi-Fi 到蜂窝网络）时，连接 ID 不变，避免了 TCP 因 IP 变化导致的重连。
2. **用户态协议栈**：QUIC 的拥塞控制、流量控制等功能在应用层实现，无需依赖操作系统内核。这使得协议升级更灵活，例如 B 站通过 QUIC 优化了视频卡顿率（降低 5%）和首帧加载速度（提升 10%）。
3. **强制加密**：QUIC 内置 TLS 1.3，所有数据默认加密，避免了 HTTP/2 中可能存在的明文传输风险。

### 总结

HTTP/3 的改变本质上是**传输层协议的范式革命**：通过 UDP 的灵活性和 QUIC 的创新设计，彻底解决了 TCP 的性能瓶颈，同时保留了可靠传输的核心需求。这一改变尤其对移动网络、高延迟环境和实时应用（如视频、游戏）意义重大。尽管目前 HTTP/3 的普及度仍低于 HTTP/2，但随着浏览器和服务器的逐步支持（如 Chrome、Firefox 默认启用），它已成为优化现代网络体验的关键技术。

## 转发和重定向的区别是什么？

在 Web 开发中，**转发（Forward）**和**重定向（Redirect）**都是将请求从一个地方转发到另一个地方的技术手段，但它们在工作机制、用途和效果上存在一些关键的区别。

| 特性     | 转发（Forward）        | 重定向（Redirect）                           |
| -------- | ---------------------- | -------------------------------------------- |
| 请求处理 | 服务器内部处理请求     | 客户端发起新请求                             |
| URL变化  | 不变化                 | URL 变化                                     |
| 请求共享 | 可以共享请求属性       | 不能共享请求属性                             |
| 性能     | 性能较好（无额外请求） | 性能较差（有额外请求）                       |
| 适用场景 | 同一应用内的逻辑转移   | 需要用户重新请求的场景，例如登录、表单提交后 |

### 转发（Forward）

1. **概念**：
    - 转发是由服务器内部处理请求，原请求的控制权转移到另一个资源（如 JSP、Servlet）上，但客户端并不知道这一变化。
2. **工作机制**：
    - 使用 `RequestDispatcher` 的 `forward()` 方法来实现。服务器将请求和响应对象直接传递给目标资源。
    - URL 不会改变，浏览器的地址栏依然显示原始请求的 URL。
3. **用途**：
    - 常用于在同一服务器上将请求转发到另一个处理逻辑上，例如在某个 Servlet 中处理完业务逻辑后，将请求转发到 JSP 页面进行结果展示。
4. **性能**：
    - 转发过程相对较快，因为没有额外的 HTTP 请求和响应的创建，所有操作都在服务器内部完成。
5. **请求对象的共享**：
    - 转发后，原请求的属性（如通过 `request.setAttribute()` 设置的属性）可以在目标资源中访问。

### 重定向（Redirect）

1. **概念**：
    - 重定向是服务器向客户端发出新的请求指令，告诉浏览器去请求另一个 URL。浏览器会创建一个新的请求。
2. **工作机制**：
    - 使用 `HttpServletResponse` 的 `sendRedirect()` 方法来实现。服务器返回一个 3xx 状态码（通常是 302），并在响应头中指定新的 URL。
    - 浏览器会根据这个 URL 发送新的请求，地址栏中的 URL 会更新为新的 URL。
3. **用途**：
    - 常用于需要更新 URL 的场景，比如表单提交后重定向到一个结果页面，或实现用户权限控制时，将未登录用户重定向到登录页面。
4. **性能**：
    - 重定向涉及到一次完整的 HTTP 请求过程（原请求 + 重定向请求），因此性能相对较慢。
5. **请求对象的共享**：
    - 重定向后，原请求的属性不能直接共享，因为它们在两个不同的请求中。若需要传递数据，通常使用 URL 参数、会话（Session）或 Cookie。


## 绕过 Cookie 继续运行 Session

1. **URL 中携带 SessionID**：可以通过 URL 重写的方式将 Session ID 添加到所有的 URL 中。服务器生成 Session ID 后，将其作为 URL 的一部分传递给客户端，客户端在后续的请求中将 Session ID 带在 URL 中。服务器端需要相应地解析 URL 来获取 Session ID，并维护用户的会话状态。
2. **隐藏表单字段传递 SessionID**：将 Session ID 添加到 HTML 表单的隐藏字段中。在每个表单中添加一个隐藏的字段，保存 Session ID，客户端提交表单时会将 Session ID 随表单数据一起发送到服务器，服务器通过解析表单数据中的 Session ID 来获取用户的会话状态。

这些方法虽然可以在禁用 Cookie 的情况下继续使用 Session，但需要在服务器端进行相应的代码修改和配置。但同时这些手段也带来了以下几个新问题：

1. **增加了编码复杂度**：需要改前端和后端代码才能继续使用 Session 机制，增加了编码复杂度。
2. **增加了安全风险**：这些替代方法可能会增加一些安全风险，因为 Session ID 将以明文形式出现在 URL 或表单中，很容易被第三方劫持和获取




## 为什么要先用非对称算法加密，后面又用对称算法？


### 先理解两种算法的核心特点：

- **对称加密算法**（如 AES、DES）：
  加密和解密使用**同一个密钥**（对称密钥），特点是：
   - 优点：加密速度极快（适合处理大量数据，如文件、视频、长文本），计算开销小。
   - 缺点：**密钥传输问题**―― 如果通信双方要使用对称加密，必须先把对称密钥传给对方，但直接传输密钥时，一旦被黑客截获，后续所有加密数据都会被破解。
- **非对称加密算法**（如 RSA、ECC）：
  加密和解密使用**一对不同的密钥**（公钥和私钥）：公钥可以公开，任何人都能用公钥加密数据，但只有对应的私钥才能解密；反之，用私钥加密的数据，只有公钥能解密。特点是：
   - 优点：**无需传输私钥**，只需公开公钥即可安全传输加密信息（比如用对方公钥加密的数据，只有对方的私钥能解密），解决了 “密钥传输安全” 问题。
   - 缺点：加密速度很慢（比对称算法慢 100-1000 倍），不适合处理大量数据（比如加密一个 1GB 的文件，耗时会非常长）。

### 为什么要 “先非对称、后对称”？

单独使用任何一种算法都有明显缺陷：



- 若只使用对称加密：密钥传输不安全，一旦密钥泄露，整个通信被破解。
- 若只使用非对称加密：加密大量数据时效率极低，无法满足实际通信需求（比如视频通话、文件传输）。



**混合策略的逻辑**：



1. **先用非对称算法解决 “对称密钥的安全传输”**：
   通信双方先通过非对称算法交换一个 “临时的对称密钥”。例如：
   - A 生成一个随机的对称密钥（比如 AES 密钥）；
   - A 用 B 的公钥加密这个对称密钥，然后发给 B；
   - B 收到后，用自己的私钥解密，得到对称密钥。
     由于公钥加密的数据只有私钥能解密，这个过程中对称密钥不会被黑客截获。
2. **再用对称算法加密后续的大量数据**：
   双方拿到相同的对称密钥后，后续所有通信数据（比如聊天内容、文件、视频流）都用这个对称密钥加密。
   由于对称算法速度极快，即使处理海量数据也能保证效率，同时因为密钥是通过非对称算法安全传输的，整体通信是安全的。

### 典型应用场景：HTTPS 协议

HTTPS 是这种混合策略的典型案例：



- 客户端（浏览器）和服务器先通过 “非对称加密”（如 RSA）完成 “对称密钥”（如 AES 密钥）的交换（这个过程叫 “握手”）；
- 握手结束后，后续所有 HTTP 数据的传输都用这个对称密钥加密，既保证安全，又不影响浏览速度。

### 总结

“先非对称、后对称” 的本质是：



- 用非对称算法的 “密钥管理优势” 解决对称密钥的安全传输问题；
- 用对称算法的 “高效加密优势” 处理大量数据的加密需求。
  两者结合，既满足了安全性，又保证了效率，是目前主流加密通信的标准方案。