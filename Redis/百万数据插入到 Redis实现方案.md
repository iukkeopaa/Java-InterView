### **一、基础优化：减少网络往返与命令开销**

#### 1. 使用 Redis 批量命令（优先推荐）

Redis 提供了针对特定数据结构的**原生批量命令**，这些命令通过单条请求处理多条数据，天然减少网络往返（一次请求处理 N 条数据），效率远高于单条命令循环插入。

- **适用场景**：数据结构单一（如纯键值对、哈希表、集合等）。
- **常用命令**：
    - 键值对（String）：`MSET key1 val1 key2 val2 ...`（一次最多支持 2^32-1 个键值对，实际建议每批≤1000 条，避免命令过长）。
    - 哈希表（Hash）：`HSET hashKey field1 val1 field2 val2 ...`（替代旧的`HMSET`，支持批量设置字段）。
    - 集合（Set）：`SADD setKey member1 member2 ...`。
    - 有序集合（ZSet）：`ZADD zsetKey score1 member1 score2 member2 ...`。
    - 列表（List）：`LPUSH listKey val1 val2 ...` 或 `RPUSH`（批量插入列表元素）。
- **优势**：单条命令处理批量数据，Redis 内部执行效率最高，网络往返最少。
- **注意**：单批数据量不宜过大（建议 1000-5000 条 / 批），避免命令数据包过大导致网络超时或 Redis 单次处理阻塞（Redis 是单线程，单条命令执行时间过长会阻塞其他请求）。

#### 2. 使用 Pipeline（管道）批量发送命令

当需要插入的命令没有原生批量命令（如混合数据结构、复杂逻辑命令）时，使用**Pipeline**机制：客户端一次性发送多个命令，Redis 批量处理后一次性返回结果，避免 “发送 - 等待 - 接收” 的循环，大幅减少网络延迟。

- **适用场景**：多数据结构混合插入、无原生批量命令的场景（如带过期时间的键值对`SET key val EX 10`）。

- **操作方式**：

    - 客户端（如 Jedis、Redisson、Python 的 redis-py）通过 Pipeline 接口批量添加命令，最后执行`exec()`发送。

    - 示例（Python 伪代码）：

      python



    运行

    

    

    

    

    ```python
    import redis
    r = redis.Redis()
    pipe = r.pipeline()
    for i in range(1000000):
        pipe.set(f"key:{i}", f"val:{i}")
        # 每1000条执行一次，避免管道缓存过大
        if i % 1000 == 0:
            pipe.execute()
    pipe.execute()  # 处理剩余数据
    ```

- **优势**：通用型强，支持任意命令组合，效率接近原生批量命令。

- **注意**：同批量命令，需控制每批大小（建议 1000-2000 条 / 批），避免客户端内存占用过高或 Redis 处理超时。

### **二、高效导入工具：redis-cli --pipe 模式**

对于通过文件或脚本生成的大量数据，可使用 Redis 官方提供的`redis-cli --pipe`模式，这是**性能最优的批量插入方式之一**（接近 Redis 内存写入极限）。

- **原理**：通过管道将数据以 Redis 协议格式写入`redis-cli`，工具直接解析协议并批量发送，避免客户端层的序列化 / 解析开销。

- **操作步骤**：

    1. 生成符合 Redis 协议的文本文件（每行一条命令的协议格式）。

       例如，插入

       ```
       key1=val1
       ```

       、

       ```
       key2=val2
       ```

       的协议格式为：

       plaintext











     ```plaintext
     *3\r\n$3\r\nSET\r\n$4\r\nkey1\r\n$4\r\nval1\r\n
     *3\r\n$3\r\nSET\r\n$4\r\nkey2\r\n$4\r\nval2\r\n
     ```

     （可通过脚本自动生成，如 Python 的

     ```
     redis.protocol
     ```

     模块）。

2. 通过管道导入：

   bash











     ```bash
     cat data.txt | redis-cli -h host -p port --pipe
     ```

- **优势**：纯协议层传输，无额外开销，单实例插入速度可达 10 万 +/ 秒（视网络和 Redis 性能）。

- **适用场景**：离线数据导入（如从文件、数据库导出后批量写入 Redis）。

### **三、分布式并行：利用集群分片（Sharding）**

如果 Redis 是**集群模式**（多节点分片），可将百万级数据按分片规则（如哈希分片）分散到不同节点，**并行插入**提升效率。

- **原理**：集群中每个节点负责一部分哈希槽，将数据按`CRC16(key) % 16384`分配到对应节点，多节点同时处理插入，总吞吐量 = 单节点吞吐量 × 节点数。
- **操作方式**：
    - 使用集群客户端（如 JedisCluster、Redis Cluster 客户端），客户端会自动根据 key 的哈希槽路由到对应节点。
    - 若手动分片，可按节点数量拆分数据（如 100 万条数据分给 3 个节点，每个节点处理～33 万条），多线程分别连接不同节点插入。
- **优势**：突破单节点性能瓶颈，适合超大规模数据（千万级以上）。
- **注意**：确保数据均匀分布，避免个别节点负载过高；需处理集群重定向（MOVED/ASK）逻辑（客户端通常自动处理）。

### **四、环境与配置优化：减少 Redis 内部开销**

插入过程中，Redis 的**持久化、内存碎片、网络配置**等会影响效率，可临时优化：

1. **关闭持久化（临时）**：
   插入时暂时关闭 RDB（`save ""`）和 AOF（`config set appendonly no`），避免 IO 写入消耗 CPU / 内存。插入完成后再恢复配置（需手动触发一次 RDB 或等待 AOF 重写）。
   *风险*：若插入过程中 Redis 宕机，数据会丢失，适合非核心数据或可重入场景。
2. **调整内存分配**：
   确保 Redis 有足够内存（避免 swap），可通过`config set maxmemory-policy noeviction`关闭内存淘汰（避免插入时淘汰旧数据），插入后恢复策略。
3. **优化网络配置**：
   客户端与 Redis 同机房部署（减少网络延迟）；增大 TCP 缓冲区（`sysctl -w net.core.wmem_max=16777216`），减少网络包分片。

### **五、客户端细节优化**

1. **使用连接池**：
   复用 TCP 连接，避免频繁创建 / 关闭连接的开销（如 JedisPool、redis-py 的 ConnectionPool）。
2. **高效序列化**：
   若存储复杂对象，使用二进制序列化（如 Protocol Buffers、MsgPack）替代 JSON / 字符串，减少数据传输大小（如 100 万条数据，每条节省 100 字节，总节省 100MB）。
3. **分批次插入**：
   无论用哪种方式，均需分批次（如每批 1000-5000 条），避免单次命令过大导致：
    - 客户端内存溢出（缓存过多命令）；
    - Redis 单命令执行时间过长（超过`timeout`配置）；
    - 网络超时（数据包过大传输耗时久）。

### **总结：方案选择建议**

- **小批量（10 万级）**：直接用批量命令（MSET 等）或 Pipeline。
- **中批量（百万级）**：优先`redis-cli --pipe`（文件导入）或 Pipeline 分批次，配合关闭持久化。
- **超大量（千万级 +）**：集群分片 + 并行插入，结合上述所有优化（批量命令、关闭持久化、连接池）。

核心原则：**减少网络往返次数**（批量 / Pipeline）、**降低 Redis 内部消耗**（关闭持久化）、**利用并行能力**（集群分片）。